<!DOCTYPE html>
<html lang="en">
<head>
    <title>AICRES</title>
    <meta property="og:title" content="AICRES"/>

    <link rel="stylesheet" type="text/css" href="css/style.css">
</head>

<body>

<!-- Title -->
<br>
<center>
    <span style="font-size:38px">AICRES: Artificial Intelligence Crisis Active Risk REduction System for Blind and VisuallyImpaired</span>
</center>


<!-- Organizations -->
<br>
<table align=center width=900px>
    <tr>
        <td align=center width=100px>
            <center>
                <span style="font-size:20px"><a href="http://mmvc.engineering.nyu.edu/">
                    NYU Multimedia and Visual Computing Lab, NYU Abu Dhabi and Tandon</a> </span>
            </center>
        </td>
    </tr>
</table>



<!-- Teaser figure -->
<br>
<table align=center width="1024px">
    <tr>
        <td width="900px">
            <center>
                <img src="./resources/pro2_1.png" width="1024px">
            </center>
        </td>
    </tr>
</table>

<!-- Research Statement -->
<center><h1>Research Statement</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           There are 39 million blind and 246 million individuals with low vision worldwide, according
            to the World Health Organization (WHO). Before the arrival of the pandemic,
            the sight loss and low vision pose significant challenges for the visually impaired (VI)
            individuals to carry out activities of daily livings. An April 2020 survey
            conducted by American Foundation for the Blind with over 1921 participants revealed that sudden pandemic crises
            like the ongoing COVID-19 profoundly magnified those barriers and obstacles in daily lives of the VI,
            creating more hardships than ever before for the VI community.
            According to the survey, the top healthcare concern was touching things in public
            such as elevator panels, self-serve kiosks, or restroom doors to check signage; the top social concern was about
            social distancing, especially when trying to get help from others while walking or shopping; regarding
            transportation, VIs were concerned about safety from viruses. Those concerns are raised mainly because
            VIs have limited perceptive range so they use haptics much more frequently than the healthy-sighted in
            their everyday lives to locate objects, acquire object details, or navigate scenes (e.g. reading braille
            and feeling tactile signs). The shortened perceptive range of the VI and the elevated pandemic risks that
            result from it motivate us to propose our project which aims to develop a wearable solution to augment
            the VI's perceptive power, so they can perceive events and objects in their surrounding environment in
            a touch-less and/ or -free manner and consequently carry out activities of daily living during pandemics
            more intuitively, safely, and independently. We name the proposed wearable solution <b>AI-CARES</b>:
            <b>A</b>rtificial <b>I</b>ntelligence <b>C</b>risis <b>A</b>ctive <b>R</b>isk R<b>E</b>duction
            <b>S</b>ystem.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Research Objectives -->
<hr>
<br>
<center><h1>Research Objectives</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
            The design requirements of a wearable device for the risk reduction during a pandemic are quite demanding.
            On the one hand, it needs to reliably recognize key items in a 3D environment with a compact wearable device
            and accurately inform the VI about the environment and potential risk. On the other hand, it should also enable
            VI to actively explore and interact with the environment freely without relying on excessive touch. To this end,
            our proposed AI-CARES is designed with two modes of operation: passive and active and will be equipped with the
            following features:
        </p>
        <p align="justify" style="font-size: 18px">(1) Responsive detection and alert of potential risks such as obstacles and dense crowds.  </p>
        <p align="justify" style="font-size: 18px">(2) Two-way communication between the user and environment: the user should be allowed to not only stay informed
            of their surroundings but also interact safely with their surroundings.</p>
        <p align="justify" style="font-size: 18px">(3) Highly computational efficiency to
            allow for real-time processing of visual data within a compact device (i.e. smartphone).</p>
        <p align="justify" style="font-size: 18px">(4) Highly portable design:
            the device does not require dedicated sensors or processors to be as portable as possible.
        </p>
        <p>
                        (5) VI-user friendly interface to convey notifications, alerts, and commands.
        </p>
    </td>
</tr>
<tr></tr>
</table>

<!-- Approaches -->
<br>
<hr>
<center><h1>Approaches</h1></center>
<br>
<table align=center width="1024px">
    <tr>
        <td>
            <center>
                <img src="./resources/pro2_2.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/pro2_3.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/pro2_4.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>
</table>
<! -- Broader Impacts -->
<br>
<hr>
<center>
    <h1>Broader Impacts</h1>
</center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           AI-CARES uses computer vision to assist visually impaired (VI) individuals in carrying out daily
            activities national health crises like COVID-19. Due to blindness or reduced vision, the VI often
            had a lower degree of independence compared to people with regular vision. In non-pandemic times,
            VIs compensated their visual deficiencies with alternatives to vision in daily lives, like working
            with a guide person to help with grocery shopping or exploring a new environment by touch. Many of
            these compensatory methods have become risk-inducing or mentally stressing due to health and safety
            guidelines during pandemics, such as avoiding contact with object surfaces or maintaining social
            distance. At a high level, the proposed AI-CARES helps VI individuals achieve
            a higher degree of independence by offering a VI AI-powered interactive and informative perceptive
            alternatives to vision so they rely less on touch or physical assistance from another person during
            common activities. Another core part of AI-CARE is its reach-maximizing design philosophy that shapes
            its hardware and technology to be easy to obtain and intuitive to adopt.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Credit -->
<hr>
<br>
<table style="font-size:14px" align=center>
    <tr>
        <td>
            This webpage template was borrowed from <a href='../../2020/MEPS'>MEPS</a>.
        </td>
    </tr>
</table>

</body>
</html>