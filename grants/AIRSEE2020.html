<!DOCTYPE html>
<html lang="en">
<head>
    <title>AIRSEE</title>
    <meta property="og:title" content="CAREER"/>

    <link rel="stylesheet" type="text/css" href="css/style.css">
</head>

<body>

<!-- Title -->
<br>
<center>
    <span style="font-size:38px">AIRSEE: Assistive Virtual Touch Screen to Enhance Interactive
        Experience for the Blind and Visually Impaired</span>
</center>


<!-- Organizations -->
<br>
<table align=center width=900px>
    <tr>
        <td align=center width=100px>
            <center>
                <span style="font-size:20px"><a href="http://mmvc.engineering.nyu.edu/">
                    NYU Multimedia and Visual Computing Lab, NYU Abu Dhabi and Tandon</a> </span>
            </center>
        </td>
    </tr>
</table>



<!-- Teaser figure -->
<br>
<table align=center width="1024px">
    <tr>
        <td width="900px">
            <center>
                <img src="./resources/pro1_1.png" width="1024px">
            </center>
        </td>
    </tr>
</table>

<!-- Research Statement -->
<center><h1>Research Statement</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           To interactively explore the 3D surrounding environment,
            sighted people predominantly use vision to actively recognize objects at specific spatial locations ,
            actively move towards a specific destination in 3D space, and actively interact and engage with objects
            of their interests in the surrounding environment. However, sight loss and low vision profoundly affect
            a person's ability to independently carry out those activities to interactively explore the surrounding
            environment.
            Therefore, to interactively access information in and about the surrounding environment,
            blind and visually impaired (BVI) people need an assistive platform to provide intuitive
            and straightforward BVI-Environment interaction.
            To this end, the proposed research program's overall goal is to
            introduce a new assistive virtual screen (AVS) and develop an AVS-enabled
            wearable solution to enhance the interactive experience with the surrounding environment
            for BVI citizens.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Research Objectives -->
<hr>
<br>
<center><h1>Research Objectives</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
            The proposed research project, named AIRSEE: <u><b>A</b></u>ssistive V<u><b>IR</b></u>tual
            <u><b>S</b></u>creen to <u><b>E</b></u>nhance Interactive <u><b>E</b></u>xperience
            for Blind and Visually Impaired, aims to develop a computer-assisted blind and low-vision platform to
            enhance BVI's interactive experience.
            We plan to complete <u>three objectives</u> to realize our
            new concept of the assistive virtual screen to assist BVI to explore, interact, and engage with objects
            in the immediate environment.
        </p>
        <p align="justify" style="font-size: 18px"><u>1. Design of AIRSEE:</u>This objective is to conceptualize the assistive virtual screen (AVS),
            define the functional modules for the realization of AVS, and optimize software design to meet
            ''mobile-compatible'' and ''BVI-friendly'' requirements.  </p>
        <p align="justify" style="font-size: 18px"><u>2. Scene Exploration:</u>This objective is to develop visual computing algorithms to infer
            overall scene descriptions in front of the BVI user, infer the semantic features of the object
            being air-touched by the BVI user on the AVS, and relay both scene-level and object-level semantic
            information to the BVI user.  </p>
        <p align="justify" style="font-size: 18px"><u>3. Scene Interaction:</u>This objective is to develop mobile-compatible computer vision algorithms
            and implement the 3D audio algorithms into BVI-friendly applications to intuitively guide the BVI user
            to interact and engage with the objects of their interests.   </p>
    </td>
</tr>
<tr></tr>
</table>

<!-- Approaches -->
<br>
<hr>
<center><h1>Approaches</h1></center>
<br>
<table align=center width="1024px">
    <tr>
        <td>
            <center>
                <img src="./resources/pro1_2.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/pro1_3.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/pro1_4.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/pro1_5.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>
</table>
<! -- Broader Impacts -->
<br>
<hr>
<center>
    <h1>Broader Impacts</h1>
</center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           The research project intends to provide novel assistive technologies to significantly augment
            spatial cognition to transform blind and visually impaired citizens' lives.
            The success of the proposed project will have broader impacts in various ways.
            It creates social impact by advancing both the science and practical utility of using
            smartphone and machine learning approaches to develop new assistive technology to improve access
            to information for the blind and visually impaired citizens.
            The project creates benefits
            to society through a positive impact on <u>existing assistive technologies</u> with the development of
            a BVI-friendly assistive virtual screen and supporting visual computing algorithms.
            The proposed mobile-friendly visual computing algorithms for scene exploration and scene interaction
            (e.g., weakly supervised attention learning,
            faster object tracking and localization, advanced bone conduction headset compatible spatial audio) can lead
            to advanced features for current computer-vision-powered assistive devices to better assist the BVI via an
            enhanced BVI-Environment interaction experience. More importantly, the concept of the assistive virtual screen
            can potentially be integrated into current commercial Augmented reality (AR) and Virtual reality (VR) devices to
            revolutionize the way BVI people interact with the environment for improved access to information.
            The proposed project will create a positive impact on \ul{under-represented groups}.
            The benefits in terms of training, mentorship, and education of the next generation of highly qualified computer
            vision, machine learning, and wearable assistive technology professionals are already highlighted in the previous
            sections.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Credit -->
<hr>
<br>
<table style="font-size:14px" align=center>
    <tr>
        <td>
            This webpage template was borrowed from <a href='../../2020/MEPS'>MEPS</a>.
        </td>
    </tr>
</table>

</body>
</html>