<!DOCTYPE html>
<html lang="en">
<head>
    <title>cross_domain</title>
    <meta property="og:title" content="cross_domain"/>

    <link rel="stylesheet" type="text/css" href="css/style.css">
</head>

<body>

<!-- Title -->
<br>
<center>
    <span style="font-size:38px">Deep Cross-Domain Model for Conceptual Design</span>
</center>


<!-- Organizations -->
<br>
<table align=center width=900px>
    <tr>
        <td align=center width=100px>
            <center>
                <span style="font-size:20px"><sup>1</sup>MMVC Lab, New York University</span>
            </center>
        </td>
    </tr>
</table>


<!-- Research Statement -->
<center><h1>Research Statement</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           This research aims to develop a new paradigm for learning deep cross-domain (2D sketches,
3D shapes and 2D images) visual feature to improve human-computer interactions for conceptual
design. Specifically, the proposed research seeks to develop techniques to extract concise but
            informative visual features for cross-domain data, a new discriminative deep neural network model that
tends to maximize the inter-class margin while minimize the intra-class variance, and a new deep
cross-domain model for joint learning of deep visual features for data present in sketches, images
and shapes. This proposed effort will also be to develop a novel conceptual design paradigm driven
by the deep cross-domain model. This project aims to address the challenges for cross-domain
            retrieval posed by variations, noise and divergence among visual data from different domains.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Research Objectives -->
<hr>
<br>
<center><h1>Intellectual Merit</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
            The contributions of the proposed research are the development of a unified
framework based on deep neural network (DNN) for learning deep cross-domain visual features
and its engineering application of conceptual design. The proposed project leverages state-of-the-art
            techniques from multiple research domains including computational geometry, computer
vision, deep learning, human-computer interactions, and conceptual design to not only cope with
human-induced challenges such as structural variations of individual sketches and inconsistent
sketch representation, but also the challenges posed by divergence among visual data from
            different domains. The key development efforts will include:       </p>
        <p align="justify" style="font-size: 18px">1) The development of wave-kernel
based visual descriptor for cross-domain data. With the proposed descriptor,
        concise yet informative visual essences of cross-domain data will be efficiently represented; </p>
        <p align="justify" style="font-size: 18px">2) The development of two new deep neural network models, named discriminative deep auto-encoder (DDAE)
and coupled discriminative deep auto-encoder (cDDAE), to address the challenging issues in
cross-domain retrieval; </p>
        <p align="justify" style="font-size: 18px">3)The development of deep cross-domain model for engineering conceptual design. We will develop a three-channel joint learning paradigm to learn deep crossdomain visual feature for cross-domain retrieval that enables designers focus more on the cre-
ative activities of design. </p>
        <p align="justify" style="font-size: 18px">&nbsp;&nbsp;&nbsp;&nbsp;Despite the enormous success of deep learning as a technique for
feature learning in images and videos, to our knowledge, this is the first time that deep learning
is used to learn a deep cross-domain visual feature for data across domains of sketches, images
and shapes. Moreover, our proposed research is the first attempt to use deep learning to construct
deep cross-domain model for engineering conceptual design. Although the focus of the present
proposal is for cross-domain retrieval, the proposed techniques can be applied directly or be extended
        to cross-modality retrieval such as visual and text data.</p>





    </td>
</tr>
<tr></tr>
</table>

<!-- Approaches -->
<br>
<hr>
<center><h1>Approaches</h1></center>
<br>
<table align=center width="1024px">
    <tr>
        <td>
            <center>
                <img src="./resources/10_2.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/10_3.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

</table>
<! -- Broader Impacts -->
<br>
<hr>
<center>
    <h1>Broader Impacts</h1>
</center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           The proposed project will advance the state of knowledge in the broad
            areas of cross-modality and cross-domain feature learning, security, surveillance, computer vision,
computational geometry, computer graphics, and cognitive science. The results from this research
will have direct impacts in several application areas, such as 3D shape processing, multimedia
analysis, and cross-modality and cross-domain retrieval. There will be high emphasis on
            integrating student training, course developments, laboratory experiments, and dissemination into the
proposed efforts. The results of our research will be disseminated through a variety of national
and international avenues such as the CVPR, ICCV and NIPS conferences. The PIs will involve
graduate students in the proposed research, and this could become part of their thesis.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Credit -->
<hr>
<br>
<table style="font-size:14px" align=center>
    <tr>
        <td>
            This webpage template was borrowed from <a href='../../2020/MEPS'>MEPS</a>.
        </td>
    </tr>
</table>

</body>
</html>