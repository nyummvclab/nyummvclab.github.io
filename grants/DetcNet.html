<!DOCTYPE html>
<html lang="en">
<head>
    <title>detcnet</title>
    <meta property="og:title" content="detcnet"/>

    <link rel="stylesheet" type="text/css" href="css/style.css">
</head>

<body>

<!-- Title -->
<br>
<center>
    <span style="font-size:38px">DetcNet: Object Detection and Recognition in Unconstrained Scene with Deep Networks </span>
</center>


<!-- Organizations -->
<br>
<table align=center width=900px>
    <tr>
        <td align=center width=100px>
            <center>
                <span style="font-size:20px"><sup>1</sup>MMVC Lab, New York University</span>
            </center>
        </td>
    </tr>
</table>



<!-- Teaser figure -->
<br>
<table align=center width="1024px">
    <tr>
        <td width="900px">
            <center>
                <img src="./resources/6_1.png" width="1024px">
            </center>
        </td>
    </tr>
</table>

<!-- Research Statement -->
<center><h1>Research Statement</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           In our current era of versatile portable environmental sensors and artificial intelligence (AI) and computer
vision (CV) driven agent (i.e. self-driving vehicles), there has been a significant increase of interests in
the research and development of the autonomous vehicle to improve driving and fuel efficiency to help
controlling the traffic flow and parking problems. One of the key research components that drives the
            development of autonomous vehicle is the computer vision based environmental perception, through which
the autonomous vehicle (equipped with various multi-modal sensors) is guided and enabled to sense and
react to its surrounding immediate environment in order to navigate roadways without human intervention.
More specifically, the perception process often involves a sequence of visual computing subtasks such as
object classification, detection, 3D position estimation, and simultaneous localization and mapping (SLAM).
Extensive research and development is taking place on
different aspects of intelligent autonomous robotic system design, which enable many companies and re-
search laboratories to work on developing autonomous
vehicles that are capable of navigating in 3D environments, e.g., self-driving cars and self-flying drones.
Over recent years, we have also seen increasing interests among car manufacturers to develop advanced driver
assistance systems (ADAS) that alert drivers to potential problems on the road. However, many challeng-
ing issues in autonomy and compute vision still remain in the design of robust intelligent autonomous vehicles.

        </p>
        <p align="justify" style="font-size: 18px">&nbsp;&nbsp;&nbsp;&nbsp;
            We clearly need to move further beyond current ADAS
technology, with a paradigm (i.e. object detection, classification, pose estimation, and SLAM) shifting towards s
            tate of the art deep learning visual computing techniques that will allow vehicle to gain more autonomy.
To this end, the proposed project aims to start with the development of a robust object detection application
suite, named DetcNet (object detection and recognition in unconstrained scene with deep networks), as a
key component of the advanced driver assistance system (ADAS) for the autonomous vehicle. The proposed
DetcNet suite will develop deep learning algorithms for object detection from 2D image and 3D point cloud,
and the estimation of the object pose. As shown in Figure 1, DetcNet application suite consist of two main
elements DetcNet 2D and DetcNet 3D . The first element set includes a collection of various object detection
(i.e. text detection, car detection, traffic lights and signs, lane detection and pedestrian detection) as shown
in the figure. The second element set includes a collection of various 3D object detection and pose estimation.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Research Objectives -->
<hr>
<br>
<center><h1>Research Objectives</h1></center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
            The proposed research project is to develop of a novel unified framework and algorithms for vehicle-centered
real-time environmental awareness by detecting the objects of interests in a vehicles immediate surroundings.
            The approach leverages state-of-the-art techniques from multiple research domains including deep
neural network design of 2D object detection, 3D object detection and deep adversarial learning for security
mitigation for the security sensitive application of autonomous vehicles. We aim to complete the proposed
project with the following objectives:
        </p>
        <p align="justify" style="font-size: 18px">OBJECTIVE 1: Design deep neural networks for 2D object detection </p>
        <p align="justify" style="font-size: 18px">OBJECTIVE 2: Design deep neural networks for 3D object detection and pose estimation</p>
        <p align="justify" style="font-size: 18px">OBJECTIVE 3: Design deep adversarial neural networks for security mitigation</p>
    </td>
</tr>
<tr></tr>
</table>

<!-- Approaches -->
<br>
<hr>
<center><h1>Approaches</h1></center>
<br>
<table align=center width="1024px">
    <tr>
        <td>
            <center>
                <img src="./resources/6_2.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

    <tr>
        <td colspan='2'>
            <center>
                <img src="./resources/6_3.png" width="900px"/><br>
            </center>
        </td>
    </tr>
    <tr>
        <td colspan='2'>
            <center>
                <span style="font-size:18px"></span>
            </center>
        </td>
    </tr>

</table>
<! -- Broader Impacts -->
<br>
<hr>
<center>
    <h1>Project Summary</h1>
</center>
<table align=center width=900px>
<tr></tr>
<tr>
    <td width=600px>
        <br>
        <p align="justify" style="font-size: 18px">
           The merit of the proposed research project is development of a novel unified framework and algorithms for
object detection learning algorithm to better assist the autonomous car navigation. The proposed approach
leverages state-of-the-art techniques from multiple research domains including CNN, RNN, 3D geometric
feature learning ,3D environment modeling, and deep adversarial learning to address autonomous assistance
            in the complex unconstrained environments. Our proposed DetcNet is expected to gain significant
improvement on performance in both accuracy and speed on 3D object detection and pose estimation with
its complete implementation of all four critical components as descried in three objectives above.
        </p>
    </td>
</tr>
<tr></tr>
</table>


<!-- Credit -->
<hr>
<br>
<table style="font-size:14px" align=center>
    <tr>
        <td>
            This webpage template was borrowed from <a href='../../2020/MEPS'>MEPS</a>.
        </td>
    </tr>
</table>

</body>
</html>