{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.random import rand \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (4, 3)\n",
      "<class 'torch.Tensor'> torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "np_array = rand(4,3)\n",
    "print(type(np_array),np_array.shape)\n",
    "tensor = torch.FloatTensor(np_array)\n",
    "print(type(tensor),tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Process on Tensor #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cat() \n",
    "#torch.Tensor.expand()\n",
    "#torch.Tensor.squeeze() \n",
    "#torch.Tensor.repeat()\n",
    "#torch.Tensor.narrow() \n",
    "#torch.Tensor.view()\n",
    "#torch.Tensor.resize_() \n",
    "#torch.Tensor.permute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat((A,B),dim)<-> torch.chunck(A, dim)\n",
    "# Concatenates the given sequence of seq tensors in the given dimension. \n",
    "# All tensors must either have the same shape (except in the cat dimension) or be empty.\n",
    "\n",
    "zeros = torch.zeros(2,3)\n",
    "ones = torch.ones(2,3)\n",
    "\n",
    "cat1 = torch.cat((zeros,ones),dim = 0)\n",
    "cat2 = torch.cat((zeros,ones),dim = 1)\n",
    "\n",
    "print(cat1.size())\n",
    "print(cat2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.expand(tensor, scale)\n",
    "# Returns a new view of the self tensor with singleton dimensions expanded to a larger size.\n",
    "# Passing -1 as the size for a dimension means not changing the size of that dimension.\n",
    "\n",
    "singleton = torch.randn(1,3)\n",
    "\n",
    "expand = torch.Tensor.expand(singleton,(4,-1))\n",
    "\n",
    "print(singleton.size())\n",
    "print(expand.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.squeeze() = torch.squeeze(tensor, dim) <--> torch.unsqueeze(dim)\n",
    "# Returns a tensor with all the dimensions of input of size 1 removed.\n",
    "\n",
    "sigleton1 = torch.randn(3,4,1,1)\n",
    "\n",
    "squeeze1 = torch.squeeze(sigleton1)\n",
    "squeeze2 = torch.Tensor.squeeze(sigleton1)\n",
    "\n",
    "print(squeeze1.size())\n",
    "print(squeeze2.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([4, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.repeat(tesor, scale)\n",
    "# Repeats this tensor along the specified dimensions.\n",
    "# Unlike expand(), this function copies the tensorâ€™s data.\n",
    "\n",
    "zeros = torch.zeros(3,2)\n",
    "\n",
    "repeat1 = torch.Tensor.repeat(zeros,(4,2,2))#= repeat2 = zeros.repeat(4,2,2,1)\n",
    "\n",
    "print(zeros.size())\n",
    "print(repeat1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.narrow(dimension, start, length) \n",
    "# Returns a new tensor that is a narrowed version of self tensor. \n",
    "# The dimension dim is narrowed from start to start + length. \n",
    "# The returned tensor and self tensor share the same underlying storage.\n",
    "# You can also think we pick a specific slices from the original input\n",
    "\n",
    "input_tensor = torch.Tensor(([1,2,3],[4,5,6]))\n",
    "\n",
    "narrow = torch.Tensor.narrow(input_tensor,1,1,2)\n",
    "\n",
    "print(input_tensor)\n",
    "print(narrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.view(tensor, scale)\n",
    "# Returns a new tensor with the same data as the self tensor but of a different size.\n",
    "# The tensor must be contiguous() to be viewed.\n",
    "\n",
    "input_tensor = torch.randn((3,4,5))\n",
    "\n",
    "view1 = torch.Tensor.view(input_tensor,(12,5)) # =view2 = input_tensor.view(12,5)\n",
    "\n",
    "print(view1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([3, 2])\n",
      "view  torch.Size([2, 3])\n",
      "input torch.Size([4, 4])\n",
      "resize1 torch.Size([4, 4])\n",
      "resize2 torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.resize_(tensor,scale)\n",
    "# Resizes self tensor to the specified size. \n",
    "# If the number of elements is larger than the current storage size, \n",
    "# then the underlying storage is resized to fit the new number of elements. \n",
    "# If the number of elements is smaller, the underlying storage is not changed. \n",
    "# Existing elements are preserved but any new memory is uninitialized.\n",
    "\n",
    "input_tensor1 = torch.randn(3,2)\n",
    "\n",
    "view = input_tensor1.view(2,3)\n",
    "print('input', input_tensor1.size())\n",
    "print('view ',view.size())\n",
    "\n",
    "resize2 = torch.Tensor.resize_(input_tensor1,(2,2))\n",
    "resize1 = torch.Tensor.resize_(input_tensor1,(4,4))\n",
    "\n",
    "\n",
    "print('input',input_tensor1.size()) ###find the difference between view() and resize_()\n",
    "print('resize1',resize1.size())\n",
    "print('resize2',resize2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor.permute(tensor, scale)\n",
    "# Permute the dimensions of this tensor.\n",
    "\n",
    "input_tensor2 = torch.rand(3,4,5)\n",
    "tranpose = t\n",
    "\n",
    "permute = torch.Tensor.permute(input_tensor2,(2,0,1))\n",
    "\n",
    "print(permute.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Process on Varible ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25.])\n",
      "tensor([50.])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([10]),requires_grad=True)\n",
    "y = Variable(torch.Tensor([5]),requires_grad=True)\n",
    "z=x*y*5\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 5, 100, 15, 10\n",
    "x = Variable(torch.rand(N, D_in), requires_grad = False)\n",
    "y = torch.randn((N, D_out), requires_grad = False)        # Varibles and tensor share the same API\n",
    "w1 = Variable(torch.randn(D_in, H), requires_grad = True)\n",
    "w2 = Variable(torch.randn(H, D_out), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<MulBackward0 object at 0x11e214278>\n"
     ]
    }
   ],
   "source": [
    "z = 2*x\n",
    "w3 = 2*w1\n",
    "print(z.grad_fn)\n",
    "print(w3.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "for t in range(100):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2) # torch.mm() performs a matrix multiplication of the matrices mat1 and mat2.\n",
    "                                          # torch.clamp clamp all elements in input into the range [min, max] and return a resulting tensor:\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if w1.grad.sum(): w1.grad.data.zero_()\n",
    "    if w1.grad.sum(): w2.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    \n",
    "    w1.data -= learning_rate * w1.grad.data #.data pick the tensor value, .item() pick the 1-D tensor's value as an numpy number\n",
    "    w2.data -= learning_rate * w2.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Process on Module ##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5) # input of nn.Conv2d is a 4D tensor of nSamples x nChannels x Height x Width.\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x)) # x.view(x.numel()) has the same function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)                 \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:] # do not want to count batch_size\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input defination\n",
    "input = torch.randn(1,1,32,32)\n",
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.7052, -0.5608,  0.9386,  ...,  0.3902,  1.1509,  1.9225],\n",
      "          [-0.5723,  0.4903, -0.6007,  ...,  0.0484, -0.8165,  1.5653],\n",
      "          [ 0.6350,  0.7251,  0.5297,  ...,  0.7496, -0.0448, -1.5141],\n",
      "          ...,\n",
      "          [ 0.4189, -0.1265, -2.4058,  ..., -0.3103, -0.1630,  1.0984],\n",
      "          [ 0.6356,  0.2582, -0.8845,  ..., -0.1507, -0.8808,  0.7621],\n",
      "          [-0.1734, -0.0352,  0.7242,  ...,  0.2539, -0.8891,  1.3322]]]])\n",
      "tensor([ 1.4428,  0.4261,  1.0781, -0.7588, -0.7374, -0.1408, -1.5827, -1.0786,\n",
      "         0.1833, -1.2377])\n"
     ]
    }
   ],
   "source": [
    "# label and loss defination\n",
    "target = torch.randn(10)\n",
    "print(input)\n",
    "print(target)\n",
    "target = target.view(1,-1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x11d505c88>\n"
     ]
    }
   ],
   "source": [
    "# backprop and weights updates\n",
    "net.zero_grad()\n",
    "loss.backward()\n",
    "print(loss.grad_fn)\n",
    "\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n",
      "torch.Size([16, 5, 5])\n",
      "tensor([ 0.0067, -0.0125,  0.0078,  0.0244,  0.0202,  0.0027])\n"
     ]
    }
   ],
   "source": [
    "# backprop with torch.optim\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create SGD optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n",
    "\n",
    "\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
